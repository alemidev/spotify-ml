{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpotifyRNN",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPP1Z/Uy+eKag44w3XRF1vR"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbpxJHBOFuME"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# get your access token from like https://developer.spotify.com/console/get-audio-features-several-tracks/\n",
        "# accessToken = \"\"\n",
        "\n",
        "# ids of the track to use, maybe load from file and not from a list here? TODO\n",
        "ids = [\"7ouMYWpwJ422jRcDASZB7P\",\"4VqPOruhp5EdPBeR92t6lQ\",\"2takcwOaAZWiXQijPHIx7B\"]\n",
        "\n",
        "def nice(data):\n",
        "    print(json.dumps(data, indent=2, ensure_ascii=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoBuqGSHT4U_"
      },
      "source": [
        "Reference https://developer.spotify.com/documentation/web-api/reference/\n",
        "\n",
        "TODO:\n",
        "* Load a fuckton more song IDs\n",
        "* Maybe do that without getting fucked by spotify\n",
        "* Better model for evaluating songs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn5MZ6K627TY"
      },
      "source": [
        "# Load dataset\n",
        "Spotify doesn't send all the audio data together: it sends first a list with links, so we need to get each song analysis after that. This will sure be rate limited."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiELnJdJ26BZ"
      },
      "source": [
        "header = {\"Authorization\" : f\"Bearer {accessToken}\",\n",
        "                         \"Accept\": \"application/json\",\n",
        "                         \"Content-Type\": \"application/json\"}\n",
        "\n",
        "r = requests.get(f\"https://api.spotify.com/v1/audio-features/?ids=7ouMYWpwJ422jRcDASZB7P%2C4VqPOruhp5EdPBeR92t6lQ%2C2takcwOaAZWiXQijPHIx7B\",\n",
        "                headers=header)\n",
        "data = r.json()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWzVoabdBriK"
      },
      "source": [
        "features = []\n",
        "for e in data[\"audio_features\"]:\n",
        "    analysis = requests.get(e[\"analysis_url\"], headers=header).json()\n",
        "    e[\"analysis\"] = analysis\n",
        "    features.append(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yadu9itrDFzv"
      },
      "source": [
        "Ok cool, but what the fuck is this \"audio analysis\" data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oeYHgpcBYf7"
      },
      "source": [
        "sample = features[0][\"analysis\"]\n",
        "for key in sample:\n",
        "    print(key)\n",
        "print()\n",
        "# What's the difference between bars and beats and tatums?\n",
        "# nice(sample[\"segments\"])\n",
        "print(len(sample[\"segments\"]))\n",
        "nice(sample[\"track\"])\n",
        "nice(sample[\"segments\"][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj0lp1BHDWhi"
      },
      "source": [
        "The segments list contains quite some info, and there's just too much. What to use? Should probably keep into consideration the confidence.\n",
        "\n",
        "We can do a timeserie of shape (2, 12) with pitches and timbres, so the input array could be of shape (len(segments), 2, 12), and including batches (len(features), len(segments), 2, 12)\n",
        "\n",
        "Issue : len(segments) is variable! Shall we just make all features as long as the longest and fill empty samples with zeroes? We can probably make the RNN stop once the timeserie ends"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLnZ305lM946"
      },
      "source": [
        "# find the longest segments serie we have, this is sure doable with a fancy oneliner!\n",
        "max_len = 0\n",
        "for el in features:\n",
        "    max_len = max(max_len, len(el[\"analysis\"][\"segments\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIyLGwvIMwyo",
        "outputId": "e368bd69-bc82-4b3d-e9ab-dcec7ac3a83b"
      },
      "source": [
        "FEATURES = np.array((len(features), max_len, 2, 12))\n",
        "\n",
        "empty = [ [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0] ]\n",
        "\n",
        "batches = []\n",
        "for el in features: # this is also kinda ugly omg\n",
        "    buf = []\n",
        "    for seg in el[\"analysis\"][\"segments\"]:\n",
        "        buf.append([ seg[\"pitches\"], seg[\"timbre\"] ])\n",
        "    for i in range(len(buf), max_len):\n",
        "        buf.append(empty)\n",
        "    batches.append(buf)\n",
        "    print(len(batches[-1]))\n",
        "\n",
        "FEATURES = np.array(batches)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1267\n",
            "1267\n",
            "1267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-87x41qOTMm",
        "outputId": "4ceb9159-7f54-40e7-c9a3-12a788f9a2cd"
      },
      "source": [
        "FEATURES.shape # now the shape should be proper"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1267, 2, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdLMpy7UHvVg"
      },
      "source": [
        "# How to make labels\n",
        "This is quite a spicy topic. We can maybe rank a n-dim space by comparing distance from the position it gives to tracks and distance in the way-less-than-n-dim space that spotify gives. For now we can just use the vector spotify gives us as labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qzd_kUSjDA38"
      },
      "source": [
        "sample = features[0]\n",
        "for key in sample:\n",
        "    print(key)\n",
        "\n",
        "# We can use [danceability, energy, key, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo]\n",
        "#       shape of sample label : (11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w11_Rn0CIoXM"
      },
      "source": [
        "LABELS = np.empty((len(features), 11)) # len(labes) : 11\n",
        "\n",
        "for i in range(len(features)):\n",
        "    # lmao my numpy game is so rusty\n",
        "    LABELS[i][0] = features[i][\"danceability\"]\n",
        "    LABELS[i][1] = features[i][\"energy\"]\n",
        "    LABELS[i][2] = features[i][\"key\"]\n",
        "    LABELS[i][3] = features[i][\"loudness\"]\n",
        "    LABELS[i][4] = features[i][\"mode\"]\n",
        "    LABELS[i][5] = features[i][\"speechiness\"]\n",
        "    LABELS[i][6] = features[i][\"acousticness\"]\n",
        "    LABELS[i][7] = features[i][\"instrumentalness\"]\n",
        "    LABELS[i][8] = features[i][\"liveness\"]\n",
        "    LABELS[i][9] = features[i][\"valence\"]\n",
        "    LABELS[i][0] = features[i][\"tempo\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wugq3KebLt0b",
        "outputId": "c5862718-6ede-4ba4-c0df-b930afe0979a"
      },
      "source": [
        "LABELS.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l76CDYKYQofE"
      },
      "source": [
        "# Estimating model size and params\n",
        "To see if this is feasible and with what model/hyperparams, let's first make a model that classifies the songs same way spotify did, using their properties directly as labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvY1BWLqUGdL"
      },
      "source": [
        "Model talk: we should definitely not just flatten the input but have a RNN use the timeserie property, so we \"get rid of first dim\". 2 other dims can be merged into one before with a Conv2D layer probably. Then some layers of LSTM / GRU. Output for now will be a Dense with 11 neurons but just to make it regenerate the spotify labels while messing with the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7dQm7C5RD07"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.Input(shape=(len(FEATURES[0]), 2, 12)),\n",
        "                             tf.keras.layers.Flatten(), # Sure, let's just flatten it and lose so much useful info\n",
        "                             tf.keras.layers.Dense(100),\n",
        "                             tf.keras.layers.Dense(50),\n",
        "                             tf.keras.layers.Dense(11)\n",
        "])\n",
        "\n",
        "model.compile(loss=\"mse\", metrics=[\"accuracy\"], optimizer=\"adam\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCUqSBOYSMCw"
      },
      "source": [
        "hst = model.fit(FEATURES, LABELS, epochs=10, batch_size=1) # lmao 3 samples"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}